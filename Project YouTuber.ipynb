{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df_o = pd.read_csv('./data/USvideos.csv')\n",
    "df = df_o.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description ###  \n",
    "This dataset contains stats on U.S. based videos posted on YouTube. There are 40,949 records - each representing a video post. Each video post in the dataset contains 16 features, including: views, likes, dislikes, comment count, title, description, tags, publish date, trending date, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       category_id      views    likes  dislikes  comment_count\n",
      "count        40949      40949    40949     40949          40949\n",
      "mean            19    2360784    74266      3711           8446\n",
      "std              7    7394113   228885     29029          37430\n",
      "min              1        549        0         0              0\n",
      "25%             17     242329     5424       202            614\n",
      "50%             24     681861    18091       631           1856\n",
      "75%             25    1823157    55417      1938           5755\n",
      "max             43  225211923  5613827   1674420        1361580\n"
     ]
    }
   ],
   "source": [
    "print(df.describe().astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Description\n",
    "\n",
    "**1. Category ID:** The category of the video. \n",
    "**2. Views:** On average, the videos in this dataset received 2,360,784 views. The median received 681,861; while the max received 225,211,923. The outliers are driving the average higher.   \n",
    "**3. Likes:** Likes variable share similar charecteristics as views.  \n",
    "**4. Dislikes:** Dislikes variable share similar charecteristics as views.    \n",
    "**5. Comment Count:** Comments variable share similar charecteristics as views.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments_disabled           bool\n",
      "ratings_disabled            bool\n",
      "video_error_or_removed      bool\n",
      "category_id                int64\n",
      "views                      int64\n",
      "likes                      int64\n",
      "dislikes                   int64\n",
      "comment_count              int64\n",
      "video_id                  object\n",
      "trending_date             object\n",
      "title                     object\n",
      "channel_title             object\n",
      "publish_time              object\n",
      "tags                      object\n",
      "thumbnail_link            object\n",
      "description               object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# What are the column types?\n",
    "# Descriptive stats of Comment Count, Likes and Dislikes are skewed as some videos have comments and/or reviews disabled. \n",
    "print(df.dtypes.sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables Summary ###\n",
    "Dataset seems to have large outliers that are driving these numbers out of wack.  \n",
    "  \n",
    "Descriptive stats for Comment Count, Likes and Dislikes are skewed as some videos have comments and/or reviews disabled.  \n",
    "Normalizing the stats by eliminating those videos that have disabled ratings and comments might make the dataset more useful.\n",
    "\n",
    "### What's the goal? ###  \n",
    "**VIEWS** is the currency of YouTubers. The more views one gets, the more subscribers, followers and money they make. Our goal is to ask questions in relation to views.  \n",
    "\n",
    "While the variables that the dataset provided seems useful, I'd like to know the video length to do analysis on views. I suspect that shorter videos receive more views, reiviews and/or comments. If that is the case, then when we post videos on YT, our video length should be within that range that experiences more views.\n",
    "  \n",
    "In order to answer this question, we must reach out to YouTube - either by scraping the length of each video or accessing the YT API to get this data.  \n",
    "  \n",
    "Additionally, once we normalize the data and retrieve all the additional variables through scraping and feature engineering, we'll run a regression analysis to better understand the relationship and impact of the variables on video views.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Plan/Questions ###  \n",
    "**Tags:** How many tags does each video have? Does the more tags a video have garner more views, given its more discoverable? Does having an overwhelming amount of tag hurt you?  \n",
    "  \n",
    "**Description:** Does the length of the description help or hurt views?  \n",
    "  \n",
    "**Title:** Does the length of the title play a role in receiving more views? Do similar titles cannabalize views?  \n",
    "  \n",
    "**Channel Title:** Are there similar sounding channels? Maybe too many similar sounding channels cannabalize each others views?\n",
    "\n",
    "**Publish and Trending Date:** On average, how long does it take for a video to go treding? What are the characteristics of the videos with the long lead time vs those with short lead time?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags ###\n",
    "Tags look like they are seperated by the pipe symbol. Each tag after the first tag has quotes which should be scrubed.  \n",
    "We'll create a column to seperate and count each tag, as well as count duplicate tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    NFL|\"Football\"|\"offense\"|\"defense\"|\"afc\"|\"nfc\"...\n",
       "11    The Walking Dead|\"shiva\"|\"tiger\"|\"king ezekiel...\n",
       "12    marshmello|\"blocks\"|\"marshmello blocks\"|\"block...\n",
       "13    nowthis|\"nowthis world\"|\"world news\"|\"nowthis ...\n",
       "14    shopping for new fish|\"new fish\"|\"aquarium fis...\n",
       "15    Robots|\"Boston Dynamics\"|\"SpotMini\"|\"Legged Lo...\n",
       "16    pacific rim|\"pacific rim 2\"|\"pacific rim seque...\n",
       "17    TED|\"TED-Ed\"|\"TED Education\"|\"TED Ed\"|\"Hilary ...\n",
       "18    ultralight|\"airplane\"|\"homemade\"|\"DIY\"|\"hoverb...\n",
       "19    SciShow|\"science\"|\"Hank\"|\"Green\"|\"education\"|\"...\n",
       "Name: tags, dtype: object"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tags'][10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One time functions\n",
    "cleanTags = lambda x: x.lower().replace('\"','').split('|')\n",
    "checkDups = lambda x: {i:cleanTags(x).count(i) for i in cleanTags(x)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate additional tag fields\n",
    "df['tags_clean'] = df['tags'].apply(cleanTags)\n",
    "df['tags_count_use'] = df['tags'].apply(cleanTags).apply(len)\n",
    "df['tags_dups'] = df['tags'].apply(checkDups)\n",
    "df['tags_dups_count_use'] = df['tags_dups'].apply(dict.values).apply(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description ###  \n",
    "Very unscrutured. The only thing we can get from here is the length of the string.  \n",
    "  \n",
    "For additional analysis, we should see if the tags are present in the description. This will help us answer the question: are tags an addition to the description or should they contain duplicate terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description_count_use'] = df['description'].apply(str).apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title ###  \n",
    "Similar to Description, we should get the length of the title.  \n",
    "  \n",
    "For additional analysis, we should see if the tags are present in the title. If so, what position in the title does the tag take: beginning, middle, end? This will help us answer the question: are tags an addition to the title or should they contain duplicate terms. Also, this analysis could help us understand the importance of tags - do the search algorithm prioritize search results based on tag relevancy to the title?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tile_count_use'] = df['title'].apply(str).apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish and Trending Date ###  \n",
    "Both variables need to be normalized as they are both in different formats.  \n",
    "We will get the difference between trending and publish date. This will give us insight into, on average, how long do we have to wait for our video to go trending? Additionally, what is the relationship between trending lead time and the length of the video? Do shorter videos trend faster?  \n",
    "  \n",
    "Additionally, we will tease out the time it was published. For videos that trend on the same date it was published, the time it was published might give us an insight into when we should release our video to the public. I assume that prime time is the best time to publish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_time</th>\n",
       "      <th>trending_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-11-13T02:05:26.000Z</td>\n",
       "      <td>17.14.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-11-13T03:00:00.000Z</td>\n",
       "      <td>17.14.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-11-13T17:00:00.000Z</td>\n",
       "      <td>17.14.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-11-12T14:00:00.000Z</td>\n",
       "      <td>17.14.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-11-12T18:30:01.000Z</td>\n",
       "      <td>17.14.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017-11-13T20:09:58.000Z</td>\n",
       "      <td>17.14.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017-11-12T17:00:05.000Z</td>\n",
       "      <td>17.14.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017-11-13T16:00:07.000Z</td>\n",
       "      <td>17.14.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017-11-13T15:30:17.000Z</td>\n",
       "      <td>17.14.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017-11-12T22:00:01.000Z</td>\n",
       "      <td>17.14.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                publish_time trending_date\n",
       "10  2017-11-13T02:05:26.000Z      17.14.11\n",
       "11  2017-11-13T03:00:00.000Z      17.14.11\n",
       "12  2017-11-13T17:00:00.000Z      17.14.11\n",
       "13  2017-11-12T14:00:00.000Z      17.14.11\n",
       "14  2017-11-12T18:30:01.000Z      17.14.11\n",
       "15  2017-11-13T20:09:58.000Z      17.14.11\n",
       "16  2017-11-12T17:00:05.000Z      17.14.11\n",
       "17  2017-11-13T16:00:07.000Z      17.14.11\n",
       "18  2017-11-13T15:30:17.000Z      17.14.11\n",
       "19  2017-11-12T22:00:01.000Z      17.14.11"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['publish_time', 'trending_date']][10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create singleton, lambda functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "getTime = lambda x: str(datetime.datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.000Z').time())\n",
    "getDate = lambda x: datetime.datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.000Z').date()\n",
    "getDateFormatted = lambda x: getDate(datetime.datetime(int(x[0:2]), int(x[6:8]), int(x[3:5])).strftime('20%Y-%m-%dT%H:%M:%S.000Z'))\n",
    "getDateDifference = lambda x: x.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply functions to Dataset to create new variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['publish_time_date'] = df['publish_time'].apply(getDate)\n",
    "df['publish_time_time_use'] = df['publish_time'].apply(getTime)\n",
    "df['trending_date_date'] = df['trending_date'].apply(getDateFormatted)\n",
    "df['trend_lead_use'] = (df['trending_date_date'] - df['publish_time_date']).apply(getDateDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review New Variables ###\n",
    "Off the bat, looking at the new variables, we can clearly see that the duplicate tags calculation we generate gives us no data: almost all video posts do not have duplicate tags. We will not be using this variable.  \n",
    "  \n",
    "Additionally, some outlier analysis must be done to the trend lead variable as 75% of the video posts in this dataset had at least a 9 day trend lead. However, there are some or one exception: a max of 4,215 trend lead. We should look into this/these video post(s) and discard or fix the result to be able to use this variable efficiently.\n",
    "\n",
    "The rest off the other variables look decent enough to continuie working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       category_id      views    likes  dislikes  comment_count  \\\n",
      "count        40949      40949    40949     40949          40949   \n",
      "mean            19    2360784    74266      3711           8446   \n",
      "std              7    7394113   228885     29029          37430   \n",
      "min              1        549        0         0              0   \n",
      "25%             17     242329     5424       202            614   \n",
      "50%             24     681861    18091       631           1856   \n",
      "75%             25    1823157    55417      1938           5755   \n",
      "max             43  225211923  5613827   1674420        1361580   \n",
      "\n",
      "       tags_count_use  tags_dups_count_use  description_count_use  \\\n",
      "count           40949                40949                  40949   \n",
      "mean               19                    1                   1031   \n",
      "std                12                    0                    854   \n",
      "min                 1                    1                      1   \n",
      "25%                10                    1                    419   \n",
      "50%                19                    1                    827   \n",
      "75%                29                    1                   1388   \n",
      "max                69                    3                   5123   \n",
      "\n",
      "       tile_count_use  trend_lead_use  \n",
      "count           40949           40949  \n",
      "mean               48              16  \n",
      "std                19             146  \n",
      "min                 3               0  \n",
      "25%                34               3  \n",
      "50%                46               5  \n",
      "75%                61               9  \n",
      "max               100            4215  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe().astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
